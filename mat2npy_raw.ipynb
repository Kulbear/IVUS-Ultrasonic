{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We process the MAT files to NPY files. In addition, heavy data augmentation is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import os.path as path\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'NPY_FILES'\n",
    "source_dir = 'MAT_FILES'\n",
    "use_deconv = 'D_'\n",
    "use_patch = ''\n",
    "# use_deconv = ''\n",
    "# use_patch = 'P_'\n",
    "\n",
    "if use_patch: \n",
    "    data_dir = use_patch + data_dir\n",
    "\n",
    "if use_deconv: \n",
    "    data_dir = use_deconv + data_dir\n",
    "\n",
    "try:\n",
    "    os.listdir(data_dir)\n",
    "except:\n",
    "    os.mkdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train512x512.mat\n",
      "train512x512.mat\n",
      "(165, 512, 512)\n",
      "Generating...\n",
      "(165, 512, 512) (165, 512, 512) (165, 512, 512)\n",
      "Saving training data...\n",
      "test512x512.mat\n",
      "test512x512.mat\n",
      "(58, 512, 512)\n",
      "Saving test data...\n",
      "(58, 512, 512) (58, 512, 512)\n",
      "train256x256.mat\n",
      "train512x512.mat\n",
      "(165, 256, 256)\n",
      "Generating...\n",
      "(165, 256, 256) (165, 512, 512) (165, 512, 512)\n",
      "Saving training data...\n",
      "test256x256.mat\n",
      "test512x512.mat\n",
      "(58, 256, 256)\n",
      "Saving test data...\n",
      "(58, 256, 256) (58, 512, 512)\n",
      "train128x128.mat\n",
      "train512x512.mat\n",
      "(165, 128, 128)\n",
      "Generating...\n",
      "(165, 128, 128) (165, 512, 512) (165, 512, 512)\n",
      "Saving training data...\n",
      "test128x128.mat\n",
      "test512x512.mat\n",
      "(58, 128, 128)\n",
      "Saving test data...\n",
      "(58, 128, 128) (58, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "size = [512, 256, 128]\n",
    "dataset = ['train', 'test']\n",
    "\n",
    "train_size = 19\n",
    "test_size = 58\n",
    "\n",
    "for s in size:\n",
    "    for ds in dataset:\n",
    "        key = '{}{}x{}'.format(ds, s, s)\n",
    "        fname = '{}.mat'.format(key)\n",
    "        data = sio.loadmat(path.join(source_dir, fname))[key]\n",
    "        print(fname)\n",
    "        switch_dim = lambda x: np.rollaxis(x, -1, 0)\n",
    "        images = switch_dim(data[0][0][0])\n",
    "        \n",
    "        if use_deconv:\n",
    "            key_ = '{}{}x{}'.format(ds, 512, 512)\n",
    "            fname_ = '{}.mat'.format(key_)\n",
    "            print(fname_)\n",
    "            data_ = sio.loadmat(path.join(source_dir, fname_))[key_]\n",
    "        else:\n",
    "            key_ = key\n",
    "            fname_ = fname\n",
    "            print(fname_)\n",
    "            data_ = data\n",
    "        lumen = switch_dim(data_[0][0][1])\n",
    "        media = switch_dim(data_[0][0][2])\n",
    "\n",
    "        raw_images = images\n",
    "        raw_lumen = lumen\n",
    "        raw_media = media\n",
    "        \n",
    "        print(raw_images.shape)\n",
    "\n",
    "        if ds == 'train':\n",
    "            print('Generating...')\n",
    "            aug_images = raw_images\n",
    "            aug_lumen = raw_lumen\n",
    "            aug_media = raw_media\n",
    "            print(aug_images.shape, aug_lumen.shape, aug_media.shape)\n",
    "            print('Saving training data...')\n",
    "            np.save(\n",
    "                path.join(\n",
    "                    path.abspath('.'), data_dir,\n",
    "                    'raw_train_data_{}.npy'.format(s)), aug_images)\n",
    "            np.save(\n",
    "                path.join(\n",
    "                    path.abspath('.'),\n",
    "                    data_dir, 'raw_train_lumen_labels_{}.npy'.format(s)), aug_lumen)\n",
    "            np.save(\n",
    "                path.join(\n",
    "                    path.abspath('.'),\n",
    "                    data_dir, 'raw_train_media_labels_{}.npy'.format(s)), aug_media)\n",
    "        else:\n",
    "            print('Saving test data...')\n",
    "            np.save(\n",
    "                path.join(\n",
    "                    path.abspath('.'), data_dir,\n",
    "                    'test_data_{}.npy'.format(s)), raw_images)\n",
    "            np.save(\n",
    "                path.join(\n",
    "                    path.abspath('.'),\n",
    "                    data_dir, 'test_lumen_labels_{}.npy'.format(s)), raw_lumen)\n",
    "            np.save(\n",
    "                path.join(\n",
    "                    path.abspath('.'),\n",
    "                    data_dir, 'test_media_labels_{}.npy'.format(s)), raw_media)\n",
    "            print(raw_images.shape, raw_lumen.shape)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
